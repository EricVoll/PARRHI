\chapter{State of the Art}\label{Chap:StateOfTheArt}

The State of the Art chapter will highlight technologies and products, which contributed to this field of research. First, Augmented Reality itself will be explained and some basics will be laid out. This explanation is followed by a paragraph about current AR-Standardisations, which is important since they help developers to speed up their processes due to predefined solutions and approaches. Later, the combined field of AR and Robotics will be described in detail. Namely, how it can use Augmented Reality technology, which projects succeeded in doing so and what benefits it brought their initiators. A part about parametrised thinking and other disciplines that already utilise such an approach represents the last important separate component. A final remark describes how this thesis tries to combine all explained technologies or principles into an innovative way of programming AR applications.

\section{Augmented Reality and its standardisations}

This bachelor's thesis revolves around AR and its use cases. It is important to clearly define some terms before using them thoroughly. AR technology must not be confused with Virtual Reality (VR). Whereas VR completely immerses users, AR still allows the real world to be seen together with superimposed 3D objects projected into the user's view. T. Azuma crafted a very general definition of AR-Systems very early on \cite{azuma1997survey}. He wrote, that in order for a system to be classified as an AR system, it has to fulfil three characteristics: The system has to combine real and virtual objects, be interactive in real time and spatially map physical and virtual objects to each other. The term Augmented Reality is often used as a synonym for the also commonly used expression “Mixed Reality”. 

There are different underlying principles in AR technology. Two types of AR technologies are in use today. Firstly, there are see-through displays with strong user immersion and secondly monitor based approaches like smartphones with cameras. A large variety of producers~\cite{ARProudcersVariety} release new AR-Devices regularly.

Standards often contribute to the development and usage of technologies substantially. Firstly by unifying used technology stacks, thus potentially reducing complexity and secondly by helping new members to navigate in a complex environment. There are not many international standards on AR since the field's wide popularity still is young. Nevertheless, C.~Perey~et~al.~\cite{perey2011current} examined existing standards and some best-practice methods for AR and identified some gaps in the AR value-chain, where, as they state, are interoperability problems between different components. Another conclusion was, that there are some existing standards from other domains that could be used for AR, but there is too little agreement on which ones. The researchers lay out numerous standards for low-level implementations such as geographic location tracking, image tracking, network data transmission, etc.

Figueroa et al. \cite{figueroa2006conceptual} researched about a "Conceptual Model and Specification Language for Mixed Reality Interface Components". They want to lay a foundation for other developers to standardize 3D interface assets, for others to build upon. The team developed an XML based data structure called "3DIC" that defines the look and some smaller behaviour actions of UI control elements. Although their work features useful components, it lacks certain features that robot-human AR interfaces need like communicating with external machines and contains unwanted components like pseudo-code. "3DIC" cannot be fully processed automatically, since pseudo-code is not executable. 

Concluding from this general overview about AR technology, there does not seem to be an existing standard for HR Interfaces utilizing parametrised Augmented Reality, that allows the development of complete HR-AR-applications that can be automatically processed, executed and used. 

\section{AR in Robotic applications}
\subsection{AR during development and testing}
Wolfgang Hönig et al. examined three different use cases of Augmented Reality~\cite{hoenig2015mixed}. The research team primarily focused on the benefits offered by the co-existence of virtual and real objects during the development and testing phase. They documented three individual projects where the implementation of AR as a main feature resulted in lowered safety risks, simplified debugging and the possibility of easily modifying the actual, physical setup.

Another important dimension of development and testing is of financial nature: upfront investments and operating costs. For example, robotic aerial swarms tend to be quite expensive due to the high cost of drones. Hönig et al. successfully scaled up the number of objects in their swarms without adding physical hardware, thus, saving money and space~\cite{hoenig2015mixed}. However, it is stated that this approach might not be applicable to all experiments since simulations are never perfect replicas of actual systems. This small delta in physical behaviour might be enough to raise doubts regarding the correctness of the experiment results. 

For human-robot cooperation, behaviour induced doubts would cause great issues in the perception of the visual augmentations. Misplacing a warning hologram, for example, could harm humans nearby. According to Hönig and his colleagues, one has to put extra emphasis on this aspect. 

All projects by Hönig et al. focus on isolating certain aspects of the system to analyse and test them more flexibly, cheaply or with improved safety for all participants involved (humans and machines). Similarly, Chen et al. have created a software framework for simulating certain parts of robotic systems~\cite{chen2009mixed}. These researchers worked on methods to combine real world and simulated sensor data and navigate a real-world robot in the combined environment. Their approach was to intercept the raw sensor data originating from the real robot, and mixing it with the simulated data, before publishing it to the clients.

For the to be built AR-Human Robot Interface system, this approach could not only be used to combine the simulated virtual world and the real world data and then use it for the system's logic components but also to fully simulate the robot during the development of the system. This allows a decoupling of the development from the real world production hardware.

\subsection{Operating robotic systems with AR support}
A well-known bottleneck in robotics is the controlling of and thus, the communication with robots~\cite{RoboticsScienceMag}. In all previously cited cases, Augmented Reality was not used to enhance the interaction between humans and robots but to mitigate the current challenges in developing robotic systems. Early work by Milgram et al.~\cite{milgram1993applications} shows that even the most basic implementations of AR technology, with the objective to improve the information exchange, enhance the bidirectional communication in multiple ways. The team proposed means to relieve human operators by releasing them from the direct control loop and using virtually placed objects as controlling input parameters. This replaces direct control with a more general command process.

As Gary Klein et al. stated, communicating intent is a key issue in effective collaboration within teams~\cite{klein2005common}. Whenever robots and humans collaborate in a confined space, it is critically important to know each other’s plans or strategies in order to align and coordinate joint actions. For machines lacking anthropomorphic and zoomorphic features, such as aerial and industrial robots, it is unclear how to communicate the before-mentioned information in natural ways.

In order to solve this problem, Walker et al. \cite{walker2018communicating} explored numerous methods to utilize Augmented Reality to improve both efficiency and acceptance of robot-human collaborations via conveying the robot's intent. The group of researchers defined four methods of doing so, with varying importance being put on “information conveyed, information precision, generalizability and possibility for distraction”~\cite{walker2018communicating}. The conclusion was that spatial Augmented Reality holograms are received much more intuitively than simple 2D projected interfaces.

For the to be built system this means, that there have to be tools in place for the developer to explicitly communicate the robot's intent to the operator. There should also be ways to adapt the application's appearance to the domain in question, to maximise the acceptance of such interfaces.

\section{Parametrised Development}\label{Section:ParametricDesignIntoduction}
Numerous disciplines utilize parametrised development environments heavily. For example the CAD software \textit{CADENCE} (integrated electrical circuits) offers parametrised cells to optimize the development process~\cite{parametrizedCellElectricalInductor}. Users can place these cells and adjust certain parameters. For example, spiral inductors can be configured via a simple UI that sets the parameters in the background. Aspects like outer dimensions, metal width, number of layers, etc. can be configured. The software then calculates its properties and behaviour at runtime. Generally, there is no coding skill required.

In architecture, Parametric Design is taking overhand since the late 2000s. New capabilities in computer rendering and modelling opened up a whole new world for architects at the time. Using parametrised mathematical formulas with boundary constraints allows architects to generate building structures easier and more efficient~\cite{stavric2011parametric}. Adapting to a changing environment during the design process is much easier, since a substantial portion of work can be completed by algorithms and software applications. Additionally, the reusability of components increases massively due to the formal way of representation. Architecture studios also begin to include Virtual and Augmented Reality technologies actively in their design processes to further incorporate and better understand these new design styles called \textit{Parametric Design}~\cite{seichterDigitalDesignArch, salimSystemArchMR, wangFrameworkMXBIM}. 


\section{Current methods programming industrial robots}
To understand where and how the content of this research project fits into the world of robotics, this chapter will describe the current workflows with robots, how they are configured and programmed. It is important to know that almost all industrial robots are programmed in three distinct ways.
\begin{enumerate}
	\setcounter{enumi}{0}
	\setlength\itemsep{-1em}
	\item Teaching Pendant
	\item Simulation / Offline Programming
	\item Teaching by Demonstration
\end{enumerate}

According to the British Automation \& Robot Association, over 90\% of all industrial robots are programmed using the Teach Pendant (TP) method~\cite{bara}. Basically, these devices are touch-tablets fitted for industrial use with emergency stop buttons, more durable materials and so forth. They allow the operator to jog (a term for steering the robot manually using the TP) the robot into certain positions and offer a number of other possibilities. For easier tasks, some manufacturers (e.g. Fanuc) offer specific User Interfaces where the operator simply enters parameters and positions. More complex goals can also be achieved with the Teach Pendant by programming in a textual manner, using each manufacturer's own language. This type of programming needs a substantial amount of training and exercise.

Teach Pendants are great for trivial and simple tasks, that do not require lots of collaboration between factory components. Reprogramming the robot using this method leads to a partial downtime since the actual real robot has to be used. Important to note is, that parametrised programming already is an industry standard in industrial robotics for some brands of robots. 

Offline programming is most often used for more complex tasks and production lines. While Offline Programming is very precise and powerful, it does require a substantial amount of schooling time for the operator. Teaching by Demonstration on the other hand, is the exact opposite. Most people could succeed quickly, but the complexity of achievable tasks and the precision is limited.

The planned Augmented Reality Robot-Human Interface could be attributed to the Offline Programming category, but also interacts with the Teach Pendant mode, since the operator should be able to take over control of the robot when necessary.

\section{Combining Technologies to mitigate AR Development Challenges}

The mentioned technologies and principles from above can be combined in an attempt to mitigate challenges during AR development. The above sections of this chapter shortly describe each area of this research project's topic and analyse how and what could be used for this thesis.

Many industries are beginning to adopt Augmented Reality in their daily processes. Its advantages and challenges are clearly known and being worked on. There are numerous examples of AR helping in different environments and tasks~\cite{DiegmannBenefitsAREdu, SalaminBenefitsAR, ARInMilRepair}. Developing AR applications is generally speaking still a very costly task. On the other hand, there is the design principle of "Parametrisation", that may involve an increased initial investment, but can lower the cost of changes and adaptions to altering environments. Combining the perks of both AR technology and parametrised architecture may bear great potential.

In conclusion, there has been work done on most aspects of this bachelor's thesis' topic, which is a parametrised Augmented Reality Robot-Human Interface. Some discussed frameworks ('3DIC', \cite{figueroa2006conceptual}) allow the textual definition of AR interfaces, but lack the ability to control robotic hardware and contain unwanted components like pseudo code. The latter does not allow automatic interpreting, since pseudo code is not executable. Other projects showed the feasibility to combine simulated and real-world data to control robotic systems, but had to be programmed and developed by professional software engineers. Seemingly, there are no systems to be found that allow a simple, text-based and parametrised representation of AR interfaces, that are able to communicate with robots and allow reasonably complex applications to be built.












