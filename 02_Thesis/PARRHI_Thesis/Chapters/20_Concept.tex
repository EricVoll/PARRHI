\chapter{Concept}\label{Chap:Concept}

This chapter will explain what requirements were defined for the to be built system and how it will be designed and setup. For further reading the system will be called "Parametrised Augmented Reality Robot Human Interface" (\textit{PARRHI}).

\section{Goal}
As described in section \ref{Section:PARRHIApproach} this thesis presents a possible approach to solve the previously described problems (see section \ref{Section:ProblemDescription}). It is the main target of this bachelor's thesis to remove the necessity of high software engineering skills to develop reasonably complex Augmented Reality Robot Human Interface applications, maintaining the quality of the outcome and even increasing the degree of resuability. This might result in lower development costs, lower struggle to gather software engineering talent and even in a shorter time to market.

To succeed in this goal, a specific set of requirements has to be defined and documented in a formal way. To gather these requirements the V-Model developed by the Federal Republic of Germany was used~\cite{vmodell}.

\section{User Requirements}
Before defining the User Requirements the system's end user has to be defined. The characteristics of the actual enduser of \textit{PARRHI} might be someone who:
\begin{itemize}
	\setlength\itemsep{-1em}
	\item Knows the basics of text editing software,
	\item has no qualifications in software engineering,
	\item wants to develop an Augmented Reality application for professionals that collaborate with industrial robots in a shared perimeter.
\end{itemize}

Having an idea of the end-user, the user-requirements can be defined. The user wants to:
\begin{itemize}
	\setlength\itemsep{-1em}
	\item Develop a AR-applications without software engineering skills
	\item Have the tools necessary to create medium complex applications for use cases such as tutorials, maintenance instructions or other teaching purposes
	\item Build upon other people's work or projects
	\item Launch the AR-application on a suitable device
	\item Possibly use the same system on different types and brands of robots
\end{itemize}

\section{System Requirements}\label{Section:SystemRequirements}
Deriving from the previous chapter the System should:
\begin{enumerate}
	\setlength\itemsep{-1em}
	\item have user input in a simple and intuitive format to allow for non-software engineers.
	\item have readable and intuitive feedback on every user input.
	\item achieve reusablity by having an input in non-binary text format that allows copy and paste reproduction.
	\item support building for hand held mobile devices and head mounted Augmented Reality glasses.
	\item allow bidirectional communication with the real and virtual world in different formats
	\item allow documentation of the application's workflow
	\item be as platform independent as possible
\end{enumerate}

\clearpage
\section{PARRHI Concept}
As discussed, parametrising workflows grants a multitude of benefits (see section~\ref{Section:ParametricDesignIntoduction}). Disclosing pre-processed information to the application program via parameters, mitigates the development effort substantially by simplifying the developer's code-base, complexity and workload.  

To offer these parameters in a meaningful format, \textit{PARRHI} needs a decent model about its surroundings (see (1) in Fig. \ref{Fig:PARRHIConcept}). The model then allows to extract helpful information from complicated environments. In \textit{PARRHI's} case, this model includes the robot's forward kinematics. The developer may now use this implicitly known and automatically retrieved information in the application program (2) without necessarily understanding the source's background and mathematics. \textit{PARRHI} will retrieve, calculate and update these parameters at runtime, "filling in the gaps".

The parametrised program (2) is an exchangeable document, provided by the application developer. Here, the application's workflow and output is defined using the afore mentioned placeholders and an additional set of tools for logic operations, also utilizing parameters. The Core Routine (3) then interprets the parametrised program and generates the output, which may act on both the virtual and real world via the Output Module (4). The real world is manipulated by (e.g.) commanding the robot in some way, whereas the virtual space may be changed by displaying UI, holograms or other augmentations. The Input Module (5) finally closes the feedback loop by sensing the environment. Information from the real world (user's position) and the robot's joint-configuration are fed into the Real World Model (1) before being combined with data about the virtual space (position and state of holograms), thereby contributing to the implicit knowledge about the environment.

Actions in both the real and virtual space may influence the other in some way. A hologram hinting the user to move their location originated in the virtual space but directly influenced the user - a real world object. Also the other way round, if a hologram is parametrised to cover the robot, the machine's movement also influences the virtual space because the parameters are updated constantly.



[Meta: These are the questions that I want to answer with the paragraphs above. "The Skeleton"]
How do I mean parametrised?
How is the system built (basic level)?
What is parametrised in my specific case?
How does the system interact with the real/virtual world?

\begin{figure}[h]
	\centering
	\includegraphics[width=0.75\textwidth]{Figures/PARRHIConcept03.jpg}
	\caption{PARRHI general concept}
	\label{Fig:PARRHIConcept}
\end{figure}


\clearpage
\subsection{Parametrised Program}

The Parametrised Program is the document, which the end user of the \textit{PARRHI} system crafts. It contains parametrised, hierarchically structured data, that defines the behaviour, feel and look of the final AR-HR-application. All instructions and definitions can make use of the previously explained parameters offered by \textit{PARRHI}. Since this is the actual document that a developer writes, its syntax and structure has to be as simple as possible to fulfil the requirements from section~\ref{Section:SystemRequirements} without limiting the user's creativity. To achieve this, a rather natural way of describing the wanted behaviour was chosen. 

The following chapters explain the set of tools that are available to the developer, how the work and interconnect. Table~\ref{Table:InputDataStructure} displays the top level structure and its main parts, where Variables, Points and Holograms define assets that Events can work with. 

\begin{table}[ht]
	\caption{\textit{Input Data} structure}
	\label{Table:InputDataStructure}
	\centering
	\begin{tabular}{lcl}
		\toprule
		Name & Section		& Explanation	\\		
		\midrule
		Variables & \ref{Section:Variables}		& Integer variables to create state machines \\
		Points& \ref{Section:Points}		& \parbox[t]{10cm}{Different kinds of 3D Point definitions\\(fix, relative to the robot, relative to the user)} 	 \\
		Holograms& \ref{Section:Holograms} & Holograms can be mounted onto points and have a set of properties\\
		Events& \ref{Section:Events} & Events have certain triggers and carry two Actions as a payload \\
		\bottomrule
	\end{tabular}
\end{table}

\subsubsection{Variables}\label{Section:Variables}
Variables are storage locations for numbers and have a symbolic name. They can be used to create different steps in one's application. When using Variables as parameters, they can be the source of an event's trigger or the target of an event's action (see section~\ref{Section:Events}) and thus take part in the application's logic. With the help of Variables an application could keep track of something by counting events, or also implement state machines that jump between modes. Variables are internal knowledge, meaning, that they are managed by the \textit{PARRHI} system and are not imported/external information.

\subsubsection{Points}\label{Section:Points}
Points probably are the best example of parametrised information in the \textit{PARRHI} system. At runtime the data from the Real World Model (see (1) in fig.~\ref{Fig:PARRHIConcept}) is directly fed into the definition of all points that use the according parameters. Thus, the system updates these objects repeatedly with Real World information, that was fed through the Real World Model.
 
Despite being parametrised themselves, Points can be used as parameters later on in the application. They essentially are a three dimensional vectors ($X$, $Y$, $Z$) that can be defined in three different ways. 
\begin{enumerate}
	\setlength\itemsep{-1em}
	\item Fix-Point
	\item Robot-Point
	\item Camera-Point
\end{enumerate}

The \textbf{Fix-Point} has static coordinates. It could be used to setup holograms that visualize certain spacial environmental constraints or for different steps in a \textit{PARRHI} AR-HR-Interface application (see figure \ref{InputData:PointFix}).

\textbf{Robot-Points} that are defined by two indexes of the robot's joints and one scalar value that defines the exact location between them (see figure \ref{InputData:PointRobot}). This is one example, where parametrised information comes into play. The application's developer does not have to understand the robot's kinematics and simply uses the joint-indexes as parameters. At runtime, the \textit{PARRHI} system retrieves the robot's joint configuration, uses the Real World Model to calculate each joint's position and then feeds this data into the Robot-Points. The final point's position is calculated as follows (with s being the scalar value and J\textsubscript{n} the position vector of Joint \textit{n} which is an output of the Real World Model):
\begin{equation}
\boldsymbol{P} = \boldsymbol{J_1} + (\boldsymbol{J_2}-\boldsymbol{J_1}) * s
\end{equation}

\textbf{Camera-Points} are a way to involve the user's position in the application. Similarly to the Robot-Points, the \textit{PARRHI} system retrieves the cameras coordinates via the Input Module, feeds it through the Real World Model to map it into the internal coordinate systems and finally periodically updates the Camera-Points with the new location data of the head mounted AR-Device.


\begin{figure}
	\begin{minipage}{0.45\textwidth}
		\centering
		\input{Figures/PointFix}
		\caption{Fix-Point example}
		\label{InputData:PointFix}
	\end{minipage}\hfill
	\begin{minipage}{0.45\textwidth}
		\centering
		\input{Figures/PointRobot}
		\caption{Robot-Point example}
		\label{InputData:PointRobot}
	\end{minipage}
\end{figure}


\subsubsection{Holograms}\label{Section:Holograms}
To actually augment the reality \textit{PARRHI} needs holograms. These elements have a number of attributes. Holograms can be active (respectively also inactive), have a render-mode, a geometric definition and of course a location. The locations are defined by a certain number of points - depending on the hologram's geometry. Currently the \textit{PARRHI} supports two types of holograms. There are spheres and cylinders, respectively taking one or two points and a radius as input parameters to define its size and position.

A Sphere's centre is always set to the point it was defined with, whereas a cylinder always connects the two points of its definition. As input points, all described types in section~\ref{Section:Points} can be used. With a given radius and point the three dimensional figure is completely defined.

Holograms have an attribute called \textit{renderMode}, which if set to "transparent", renders the hologram in a half transparent way, allowing holograms to be used for boundary or zone visualizations. Furthermore the visibility of holograms can be changed by actions as described in section~\ref{Section:Events}.

\subsubsection{Events}\label{Section:Events}
All previous elements (variables, points and holograms) exist to define the scene and to set up assets that can be utilized by events, which now actually describe the application's workflow. To do so, there are two subtypes in this category. There are event-triggers and event-actions (or short \textit{triggers} and \textit{actions}). Triggers have a boolean expression, which is checked periodically. As soon as the boolean expression evaluates to \textit{true}, the attached actions will be executed and the trigger will be disabled, avoiding multiple executions. One could say that if triggers the \textit{PARRHI's} sensors, actions are its tools to act on the augmentation. 

Triggers can be enabled and disabled, either from the beginning on, or toggled by an action. Every trigger has at least one action as a payload. To reach a reasonably capability numerous different but easy to understand triggers are available for the application's developer. In table~\ref{Table:Triggers} is a complete list of all defined triggers. \textit{(Note, that the enabled/disabled flag and actions are omitted in this table)}

 
 \begin{table}
 	\caption{Event Triggers}
 	\label{Table:Triggers}
 	\centering
 	\begin{tabular}{lll}
 		\toprule
 		Name & Input Parameter		& Trigger expression	\\		
 		\midrule
 		Distance trigger & Two Points $\boldsymbol{P_1}, \boldsymbol{P_2}$, distance $d$		&  $|\boldsymbol{P_2}-\boldsymbol{P_1}| \le d$ \\
		Variable trigger & Variable $v$, trigger value $v_{\text{tr}}$ 		& $v = v_{\text{tr}}$	 \\
		Time trigger & trigger time $t_{\text{tr}}$, time since enabling $t_{\text{enabled}}$ & $t_{\text{tr}} \geq t_{\text{enabled}}$\\
		\bottomrule
	\end{tabular}
\end{table}

\textbf{Distance trigger} can be used for two main purposes. First the application can use the robot's movement as an input using a \textit{Robot-Point}. An action could be triggered as soon as the user jogged the robot's TCP into wished position by using a \textit{Fix-Point} an waiting for them to come close to each other or to monitor the robot's configuration in Joint-Space by using two \textit{Robot-Points} as input parameters. Second the user's movement can be monitored by utilizing a \textit{Camera-Point} as an input. The application can thus ask the user to move to a specific location.

With \textbf{Variable triggers} the application is able to use defined variables as triggers. One could implement a counter for certain events, and trigger an action when a threshold value is reached. It can also be used for workflows that need states or steps. Finally the \textbf{Time trigger} allows the application to involve timers. The user could be given a maximum time for a task or holograms can be hidden after a few seconds.

Whenever a trigger's boolean expression evaluates to true, its actions are invoked and the trigger gets disabled. Since actions are the only way \textit{PARRHI} can influence the augmentation, there are numerous different types of actions - each serving a general purpose to fulfil the defined requirements (see section~\ref{Section:SystemRequirements}).

As with triggers, actions have a set of input parameters they need to fulfil their task. As with all other input data objects discussed so far, actions have a unique ID. The table~\ref{Table:Actions} gives a quick overview about all actions that \textit{PARRHI} currently supports.

\begin{table}
	\caption{Event Actions}
	\label{Table:Actions}
	\centering
	\begin{tabular}{lll}
		\toprule
		Action Name & Input Parameter		& Explanation	\\		
		\midrule
		Increment Counter  	& Variable $v$					& Increments the value of $v$ by 1 \\
		Set Hologram State 	& Hologram-IDs, State to set	& Enables/disables all specified holograms \\
		Set Trigger State  	& Trigger-IDs, State to set    	& Enables/disables all specified triggers \\
		Change UI Text	  	& Text to set					& Sets the UI Text\\
		Move Robot			& Point $P$						& Moves the robot to $P$ \\
		Set robot-hand State & State to set (open/close)		& Opens or closes the robot's gripper \\
		\bottomrule
	\end{tabular}
\end{table}

\textbf{Increment-counter actions} increment their integer variable by 1. If a developer wanted to count the number of times a user jogged the robot into a specific region, an Increment-counter action could be used as a payload of a Distance trigger. After a threshold value is reached, a Variable trigger could change the UI text and display a hint.

The \textbf{Set-Hologram-State action} enables hiding and showing holograms at runtime. If a hologram represents a region for a tutorial step, it can be hidden after the user's task is completed. The new scene can then be setup by displaying new holograms that guide the user's way. Another possible use would be, to display a warning boundary, if the user moves into a forbidden zone. This can be achieved by combining Distance trigger and Set-Hologram-State actions.

When using \textit{PARRHI} the user is presented a GUI that shows text and some other few options. The \textbf{Change-UI-Text action} allows to change this displayed text. There are numerous obvious use-cases where this is useful. Whenever it is of value to inform the user about something that cannot be achieved by holograms, this is a simple way to do so.

To create meaningful and longer applications, enabling and disabling triggers is an essential tool. This is what the \textbf{Set-Trigger-State action} is for. Triggers can only invoke their payload actions, if they are active. Triggers can either be defined as disabled from the beginning on, or get disabled by triggering as described above. The Set-Trigger-State action has the ability to (re)activate disabled triggers. There is a speciality in the case of \textit{Time triggers}. Their inner timer starts ticking, whenever they get enabled. This allows for timers to be used in the middle of applications, relative to other events.

\subsection{Interpreter}
























